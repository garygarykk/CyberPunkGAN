{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4d43ff5",
   "metadata": {},
   "source": [
    "## Edge smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e197683",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T09:37:04.382749Z",
     "start_time": "2022-11-20T09:33:29.189047Z"
    }
   },
   "outputs": [],
   "source": [
    "from GAN.edge_smooth import make_edge_smooth\n",
    "\n",
    "style_dir = '/TRAINING/neon_img/neon_img_resize'\n",
    "size = 256\n",
    "\n",
    "make_edge_smooth(style_dir, size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061c775c",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f6e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T10:13:39.296397Z",
     "start_time": "2022-11-20T10:13:39.292590Z"
    }
   },
   "outputs": [],
   "source": [
    "from GAN.dataset import NeonDataSet\n",
    "import argparse\n",
    "from multiprocessing import cpu_count\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb7945b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T11:05:12.673011Z",
     "start_time": "2022-11-20T11:05:12.626999Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', default='neon_img', type=str)\n",
    "parser.add_argument('--data_dir', default='TRAINING', type=str)\n",
    "parser.add_argument('--batch_size', default=4, type=int)\n",
    "parser.add_argument('--debug_samples', default=0, type=int)\n",
    "parser.add_argument('--num_parallel_workers', default=1, type=int)\n",
    "parser.add_argument('--epochs', type=int, default=100)\n",
    "parser.add_argument('--init-epochs', type=int, default=5)\n",
    "parser.add_argument('--batch-size', type=int, default=6)\n",
    "parser.add_argument('--checkpoint-dir', type=str, default='SAVE_POINT/checkpoints')\n",
    "parser.add_argument('--save-image-dir', type=str, default='SAVE_POINT/images')\n",
    "parser.add_argument('--gan-loss', type=str, default='lsgan', help='lsgan / hinge / bce')\n",
    "parser.add_argument('--resume', type=str, default='False')\n",
    "parser.add_argument('--use_sn', action='store_true')\n",
    "parser.add_argument('--save-interval', type=int, default=1)\n",
    "parser.add_argument('--debug-samples', type=int, default=0)\n",
    "parser.add_argument('--lr-g', type=float, default=2e-4)\n",
    "parser.add_argument('--lr-d', type=float, default=4e-4)\n",
    "parser.add_argument('--init-lr', type=float, default=1e-3)\n",
    "parser.add_argument('--wadvg', type=float, default=10.0, help='Adversarial loss weight for G')\n",
    "parser.add_argument('--wadvd', type=float, default=10.0, help='Adversarial loss weight for D')\n",
    "parser.add_argument('--wcon', type=float, default=1.5, help='Content loss weight')\n",
    "parser.add_argument('--wgra', type=float, default=3.0, help='Gram loss weight')\n",
    "parser.add_argument('--wcol', type=float, default=30.0, help='Color loss weight')\n",
    "parser.add_argument('--d-layers', type=int, default=3, help='Discriminator conv layers')\n",
    "parser.add_argument('--d-noise', action='store_true')\n",
    "args = parser.parse_args(args=[])\n",
    "plt.figure()\n",
    "\n",
    "def collate_fn(batch):\n",
    "    img, neon, neon_gray, neon_smt_gray = zip(*batch)\n",
    "    return (\n",
    "        torch.stack(img, 0),\n",
    "        torch.stack(neon, 0),\n",
    "        torch.stack(neon_gray, 0),\n",
    "        torch.stack(neon_smt_gray, 0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb34e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T11:05:16.882482Z",
     "start_time": "2022-11-20T11:05:15.544147Z"
    }
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(\n",
    "    NeonDataSet(args),\n",
    "    batch_size=args.batch_size,\n",
    "    #num_workers=cpu_count(),\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002be9ba",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff6202",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T11:05:22.431502Z",
     "start_time": "2022-11-20T11:05:22.426696Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import spectral_norm\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from GAN.conv_blocks import DownConv\n",
    "from GAN.conv_blocks import UpConv\n",
    "from GAN.conv_blocks import SeparableConv2D\n",
    "from GAN.conv_blocks import InvertedResBlock\n",
    "from GAN.conv_blocks import ConvBlock\n",
    "from GAN.utils import initialize_weights\n",
    "from GAN.image_processing import denormalize_input\n",
    "#from utils.common import load_checkpoint\n",
    "from GAN.utils import save_checkpoint\n",
    "from GAN.utils import set_lr\n",
    "\n",
    "from GAN.losses import NeonGanLoss\n",
    "from GAN.losses import LossSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f8faf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T11:05:43.730874Z",
     "start_time": "2022-11-20T11:05:43.725272Z"
    }
   },
   "outputs": [],
   "source": [
    "gaussian_mean = torch.tensor(0.0)\n",
    "gaussian_std = torch.tensor(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba422ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-20T09:11:55.688677Z",
     "start_time": "2022-11-20T09:11:55.662477Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, dataset=''):\n",
    "        super(Generator, self).__init__()\n",
    "        self.name = f'generator_{dataset}'\n",
    "        bias = False\n",
    "\n",
    "        self.encode_blocks = nn.Sequential(\n",
    "            ConvBlock(3, 64, bias=bias),\n",
    "            ConvBlock(64, 128, bias=bias),\n",
    "            DownConv(128, bias=bias),\n",
    "            ConvBlock(128, 128, bias=bias),\n",
    "            SeparableConv2D(128, 256, bias=bias),\n",
    "            DownConv(256, bias=bias),\n",
    "            ConvBlock(256, 256, bias=bias),\n",
    "        )\n",
    "\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            InvertedResBlock(256, 256, bias=bias),\n",
    "            InvertedResBlock(256, 256, bias=bias),\n",
    "            InvertedResBlock(256, 256, bias=bias),\n",
    "            InvertedResBlock(256, 256, bias=bias),\n",
    "            InvertedResBlock(256, 256, bias=bias),\n",
    "            InvertedResBlock(256, 256, bias=bias),\n",
    "            InvertedResBlock(256, 256, bias=bias),\n",
    "            InvertedResBlock(256, 256, bias=bias),\n",
    "        )\n",
    "\n",
    "        self.decode_blocks = nn.Sequential(\n",
    "            ConvBlock(256, 128, bias=bias),\n",
    "            UpConv(128, bias=bias),\n",
    "            SeparableConv2D(128, 128, bias=bias),\n",
    "            ConvBlock(128, 128, bias=bias),\n",
    "            UpConv(128, bias=bias),\n",
    "            ConvBlock(128, 64, bias=bias),\n",
    "            ConvBlock(64, 64, bias=bias),\n",
    "            nn.Conv2d(64, 3, kernel_size=1, stride=1, padding=0, bias=bias),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.encode_blocks(x)\n",
    "        out = self.res_blocks(out)\n",
    "        img = self.decode_blocks(out)\n",
    "\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,  args):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.name = f'discriminator_{args.dataset}'\n",
    "        self.bias = False\n",
    "        channels = 32\n",
    "\n",
    "        layers = [\n",
    "            nn.Conv2d(3, channels, kernel_size=3, stride=1, padding=1, bias=self.bias),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]\n",
    "\n",
    "        for i in range(args.d_layers):\n",
    "            layers += [\n",
    "                nn.Conv2d(channels, channels * 2, kernel_size=3, stride=2, padding=1, bias=self.bias),\n",
    "                nn.LeakyReLU(0.2, True),\n",
    "                nn.Conv2d(channels * 2, channels * 4, kernel_size=3, stride=1, padding=1, bias=self.bias),\n",
    "                nn.InstanceNorm2d(channels * 4),\n",
    "                nn.LeakyReLU(0.2, True),\n",
    "            ]\n",
    "            channels *= 4\n",
    "\n",
    "        layers += [\n",
    "            nn.Conv2d(channels, channels, kernel_size=3, stride=1, padding=1, bias=self.bias),\n",
    "            nn.InstanceNorm2d(channels),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Conv2d(channels, 1, kernel_size=3, stride=1, padding=1, bias=self.bias),\n",
    "        ]\n",
    "\n",
    "        if args.use_sn:\n",
    "            for i in range(len(layers)):\n",
    "                if isinstance(layers[i], nn.Conv2d):\n",
    "                    layers[i] = spectral_norm(layers[i])\n",
    "\n",
    "        self.discriminate = nn.Sequential(*layers)\n",
    "\n",
    "        initialize_weights(self)\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.discriminate(img)\n",
    "    \n",
    "def check_params(args):\n",
    "    data_path = os.path.join(args.data_dir, args.dataset)\n",
    "    if not os.path.exists(data_path):\n",
    "        raise FileNotFoundError(f'Dataset not found {data_path}')\n",
    "\n",
    "    if not os.path.exists(args.save_image_dir):\n",
    "        print(f'* {args.save_image_dir} does not exist, creating...')\n",
    "        os.makedirs(args.save_image_dir)\n",
    "\n",
    "    if not os.path.exists(args.checkpoint_dir):\n",
    "        print(f'* {args.checkpoint_dir} does not exist, creating...')\n",
    "        os.makedirs(args.checkpoint_dir)\n",
    "\n",
    "    assert args.gan_loss in {'lsgan', 'hinge', 'bce'}, f'{args.gan_loss} is not supported'\n",
    "\n",
    "\n",
    "def save_samples(generator, loader, args, max_imgs=2, subname='gen'):\n",
    "    '''\n",
    "    Generate and save images\n",
    "    '''\n",
    "    generator.eval()\n",
    "\n",
    "    max_iter = (max_imgs // args.batch_size) + 1\n",
    "    fake_imgs = []\n",
    "\n",
    "    for i, (img, *_) in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "            fake_img = generator(img. to(device))\n",
    "            fake_img = fake_img.detach().cpu().numpy()\n",
    "            # Channel first -> channel last\n",
    "            fake_img  = fake_img.transpose(0, 2, 3, 1)\n",
    "            fake_imgs.append(denormalize_input(fake_img, dtype=np.int16))\n",
    "\n",
    "        if i + 1 == max_iter:\n",
    "            break\n",
    "\n",
    "    fake_imgs = np.concatenate(fake_imgs, axis=0)\n",
    "\n",
    "    for i, img in enumerate(fake_imgs):\n",
    "        save_path = os.path.join(args.save_image_dir, f'{subname}_{i}.jpg')\n",
    "        cv2.imwrite(save_path, img[..., ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a69815",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ca00b6-be34-4263-9acb-5b674c5f247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator(args.dataset).to(device)\n",
    "D = Discriminator(args).to(device)\n",
    "\n",
    "loss_tracker = LossSummary()\n",
    "loss_fn = NeonGanLoss(args)\n",
    "\n",
    "optimizer_g = optim.Adam(G.parameters(), lr=args.lr_g, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(D.parameters(), lr=args.lr_d, betas=(0.5, 0.999))\n",
    "\n",
    "start_e = 0\n",
    "\n",
    "for e in range(start_e, args.epochs):\n",
    "    print(f\"Epoch {e}/{args.epochs}\")\n",
    "    bar = tqdm(data_loader)\n",
    "    G.train()\n",
    "\n",
    "    init_losses = []\n",
    "\n",
    "    if e < args.init_epochs:\n",
    "        # Train with content loss only\n",
    "        set_lr(optimizer_g, args.init_lr)\n",
    "        for img, *_ in bar:\n",
    "            img = img.to(device)\n",
    "\n",
    "            optimizer_g.zero_grad()\n",
    "\n",
    "            fake_img = G(img)\n",
    "            loss = loss_fn.content_loss_vgg(img, fake_img)\n",
    "            loss.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "            init_losses.append(loss.cpu().detach().numpy())\n",
    "            avg_content_loss = sum(init_losses) / len(init_losses)\n",
    "            bar.set_description(f'[Init Training G] content loss: {avg_content_loss:2f}')\n",
    "\n",
    "        set_lr(optimizer_g, args.lr_g)\n",
    "        save_checkpoint(G, optimizer_g, e, args, posfix='_init')\n",
    "        save_samples(G, data_loader, args, subname='initg')\n",
    "        continue\n",
    "\n",
    "    loss_tracker.reset()\n",
    "    for img, neon, neon_gray, neon_smt_gray in bar:\n",
    "        # To device\n",
    "        img = img.to(device)\n",
    "        neon = neon.to(device)\n",
    "        neon_gray = neon_gray.to(device)\n",
    "        neon_smt_gray = neon_smt_gray.to(device)\n",
    "\n",
    "        # ---------------- TRAIN D ---------------- #\n",
    "        optimizer_d.zero_grad()\n",
    "        fake_img = G(img).detach()\n",
    "\n",
    "        # Add some Gaussian noise to images before feeding to D\n",
    "        if args.d_noise:\n",
    "            fake_img += gaussian_noise()\n",
    "            neon += gaussian_noise()\n",
    "            neon_gray += gaussian_noise()\n",
    "            neon_smt_gray += gaussian_noise()\n",
    "\n",
    "        fake_d = D(fake_img)\n",
    "        real_neon_d = D(neon)\n",
    "        real_neon_gray_d = D(neon_gray)\n",
    "        real_neon_smt_gray_d = D(neon_smt_gray)\n",
    "\n",
    "        loss_d = loss_fn.compute_loss_D(\n",
    "            fake_d, real_neon_d, real_neon_gray_d, real_neon_smt_gray_d)\n",
    "\n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        loss_tracker.update_loss_D(loss_d)\n",
    "\n",
    "        # ---------------- TRAIN G ---------------- #\n",
    "        optimizer_g.zero_grad()\n",
    "\n",
    "        fake_img = G(img)\n",
    "        fake_d = D(fake_img)\n",
    "\n",
    "        adv_loss, con_loss, gra_loss, col_loss = loss_fn.compute_loss_G(\n",
    "            fake_img, img, fake_d, neon_gray)\n",
    "\n",
    "        loss_g = adv_loss + con_loss + gra_loss + col_loss\n",
    "\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        loss_tracker.update_loss_G(adv_loss, gra_loss, col_loss, con_loss)\n",
    "\n",
    "        avg_adv, avg_gram, avg_color, avg_content = loss_tracker.avg_loss_G()\n",
    "        avg_adv_d = loss_tracker.avg_loss_D()\n",
    "        bar.set_description(f'loss G: adv {avg_adv:2f} con {avg_content:2f} gram {avg_gram:2f} color {avg_color:2f} / loss D: {avg_adv_d:2f}')\n",
    "\n",
    "    if e % args.save_interval == 0:\n",
    "        save_checkpoint(G, optimizer_g, e, args)\n",
    "        save_checkpoint(D, optimizer_d, e, args)\n",
    "        save_samples(G, data_loader, args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8d9bf-8f3a-44f8-a2f2-ed888b0d3024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
